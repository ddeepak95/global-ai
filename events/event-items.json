[
    {
        "name": "Global AI Seminar: AI for the World of Many",
        "short_description": "**Dr. Vinodkumar Prabhakaran** is a Research Scientist at Google Research, where he co-leads the interdisciplinary Technology, AI, Society and Culture (TASC) team. His research deals with questions at the intersection of AI and society, with a focus on global and cross-cultural considerations. Before Google, he was a postdoc at Stanford University, and obtained his PhD from Columbia University. His prior research focused on building scalable ways using language technologies to identify and address large-scale societal issues such as racial disparities in policing, workplace incivility, and online abuse. He has published over 50 articles in top-tier venues such as the PNAS, ACL, TACL, NAACL, EMNLP, NeurIPS, and FAccT.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/Vinod.jpg",
        "start_date": "2026-02-10",
        "end_date": "2026-02-10",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "As Large Language Models (LLMs) are increasingly deployed globally, they encounter a ‘world of many’ --- many users, many languages, many cultural contexts, and many value systems. However, these technologies are often developed within relatively monocultural contexts, leading to significant ‘cultural incongruencies’ when deployed at scale. In this talk, I will discuss our recent research, demonstrating that crucial concepts in AI, including core safety concepts like offensiveness and harm, and even preferences for human-likeness in LLMs are not universal truths but are deeply socially situated. Drawing on cross-cultural research and datasets, we illustrate how diverse global communities perceive AI interactions differently and how current models often reproduce specific cultural stereotypes. Finally, I will close by discussing how we can integrate intentionally diversified socio-cultural data, devise pluralistic evaluations, and develop geo-culturally grounded interventions to build AI systems that are transparent, controllable, and responsive to the complexities of a global audience.",
        "speakers": []
    },
    {
        "name": "Global AI Seminar: The Making and Management of Computational Agency",
        "short_description": "**Ranjit Singh** is the director of Data & Society’s AI on the Ground program, where he oversees research on the social impacts of algorithmic systems, the governance of AI in practice, and emerging methods for organizing public engagement and accountability. His own work focuses on how people live with and make sense of AI, examining how algorithmic systems and everyday practices shape each other. His work draws on majority world scholarship, public policy analysis, and ethnographic fieldwork in settings ranging from scientific laboratories and bureaucratic agencies to public services and civic institutions. At Data & Society, he has previously led projects mapping the [conceptual vocabulary](https://datasociety.net/library/a-primer-on-ai-in-from-the-majority-world/) and [stories of living with AI](https://datasociety.net/library/parables-of-ai-in-from-the-majority-world-an-anthology/) in/from the majority world, framing the [place of algorithmic impact assessments in regulating AI](https://datasociety.net/library/assembling-accountability-algorithmic-impact-assessment-for-the-public-interest/), and investigating the [keywords that ground ongoing research into the datafied state](https://datasociety.net/library/keywords-of-the-datafied-state/).",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/Ranjit-Headshot.jpg",
        "start_date": "2026-03-03",
        "end_date": "2026-03-03",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "Computational systems increasingly act in the world in ways people experience as agency: they shape eligibility and render judgments that feel final. This talk takes that everyday attribution seriously as a way to read where power settles into routine infrastructures. Drawing on [*Parables of AI in/from the Majority World*](https://datasociety.net/library/parables-of-ai-in-from-the-majority-world-an-anthology/), I follow three linked problems that are central to thinking through contemporary AI ethics: what we count as impact, how narrative travels as evidence, and how attention gets organized. “Impact,” I argue, is a category produced through institutional routines: what gets documented, what gets compared, what gets treated as a baseline, and what gets dismissed as mere anecdote or exception. When we debate AI’s harms, we are often debating the terms of legibility, including which consequences will be made visible and which will remain outside the scope of evaluation. The talk then turns to storytelling as a method for tracing what remains out of scope for impact assessments: the work of living with computational systems, and the interpretive labor required to make those systems usable at all. I then treat attention as a social problem with technical consequences, linking the politics of what institutions choose to notice with the attention mechanisms that animate transformer models. Here, attention is allocated as time, concern, investigatory capacity, and authority. By placing these together, the talk offers a way to understand AI ethics less as a debate about designing better systems in the abstract and more as a struggle over what gets attention and by extension, becomes governable. My core argument is that making AI more just is a project of redistributing the power to define justice, including the power to decide what will count as harm, beginning with the slow discipline of listening to the ordinary.",
        "speakers": []
    },
    {
        "name": "Global AI Seminar",
        "short_description": "**Matthew Wilkens** is an Associate Professor of Information Science at Cornell University. He uses computational and quantitative methods, including natural language processing, to study large-scale literary and cultural history and other large text datasets.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2025/01/wilkens.jpg",
        "start_date": "2026-03-10",
        "end_date": "2026-03-10",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Global AI Seminar",
        "short_description": "**Matteo Zallio** is a design researcher working on inclusive and human-centered technology. His work focuses on helping organizations design environments and technologies that support inclusion, diversity, equity, and accessibility.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/matteo.jpg",
        "start_date": "2026-03-17",
        "end_date": "2026-03-17",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Global AI Seminar",
        "short_description": "**Steve Jackson** is a Professor of Information Science and Science and Technology Studies at Cornell University. His research focuses on the social and ethical dimensions of technology, including maintenance, repair, sustainability, and global inequality in technology systems.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2025/03/Jackson-Steve-2018-cropped-e1743086879126.jpg",
        "start_date": "2026-03-24",
        "end_date": "2026-03-24",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Global AI Seminar: Digital Culture Shock: Who Creates Technology and Why This Matters",
        "short_description": "**Katharina Reinecke** is a Professor and Associate Director for Research and Communication in the Paul G. Allen School of Computer Science & Engineering at the University of Washington, Seattle. She has been speaking and writing about intelligent user interfaces that seamlessly adapt to people’s cultural and demographic backgrounds for nearly two decades and has pioneered ways for reliable, large-scale data collection from participants around the world with her virtual lab, the LabintheWild. Katharina received a PhD in Computer Science from the University of Zurich and was a postdoctoral fellow at Harvard University. Prior to coming to the University of Washington, she was an Assistant Professor in the School of Information at the University of Michigan.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/KatharinaReinecke_square.jpeg",
        "start_date": "2026-04-07",
        "end_date": "2026-04-07",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "Robots that encroach on your personal space, baffling emojis, a chatbot that gives you an answer that seems terribly rude—does any of this sound familiar? If so, you may know what it feels like to experience a clash of cultures in technology. In this talk, I will present key insights from my book *Digital Culture Shock: Who Creates Technology and Why This Matters* (Princeton, 2025), showing how culture—shared values, norms, and behaviors—influences both the design of technology and its use. Drawing on a set of common assumptions that do not translate across cultures, the talk will outline what is at stake and how we can resist generalizing our own cultural peccadillos in technology design.",
        "speakers": []
    },
    {
        "name": "Global AI Seminar",
        "short_description": "**Mahika Phutane** is a Computer Science PhD researcher at Cornell University working in human interaction and AI-related computing research areas.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://mahikaphutane.com/assets/img/mahika_moni.jpeg",
        "start_date": "2026-04-14",
        "end_date": "2026-04-14",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Global AI Seminar",
        "short_description": "**Dhanaraj Thakur** is Director of the Emerging Technology Initiative at the Multiracial Democracy Project at The George Washington University Law School, where he leads research on artificial intelligence, civil rights, and democratic governance. His work focuses on how emerging technologies shape digital rights, participation, and equity in society.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/dhanaraj.jpeg",
        "start_date": "2026-04-21",
        "end_date": "2026-04-21",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Global AI Seminar",
        "short_description": "**Faisal M. Lalani** is Head of Global Partnerships at the Collective Intelligence Project and a global community organizer working across technology policy, AI governance, and digital rights, building international coalitions around public-interest technology.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/faisal.jpg",
        "start_date": "2026-04-28",
        "end_date": "2026-04-28",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Global AI Seminar",
        "short_description": "**Joshua Blumenstock** is a Chancellor’s Professor at UC Berkeley working at the intersection of machine learning and empirical economics. His research uses new data sources and computational methods to understand and reduce global poverty.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/josh-blume.jpg",
        "start_date": "2026-05-12",
        "end_date": "2026-05-12",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Global AI Seminar: Measuring AI Values",
        "short_description": "**Lionel Levine** is a Professor of Mathematics at Cornell University. He is a Fellow of the American Mathematical Society, and a past recipient of a Sloan Fellowship, NSF CAREER Award, and IAS Von Neumann Fellowship. His current research is aimed at increasing the probability that future AI systems benefit all of humanity and the planet.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://sites.coecis.cornell.edu/globalai/files/2026/02/SF1.jpeg",
        "start_date": "2026-02-24",
        "end_date": "2026-02-24",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "Aligning AI with human values is a pressing unsolved problem. But what exactly does it mean to align an AI to a given set of values? And how would one verify that a given AI is aligned? These hard questions, plus the annoying little issue of *whose* values to prioritize, led researchers at leading AI labs to aim instead for “intent alignment”: AI that (wants to) do what its developers intend.\nCan intent alignment deliver a good future, where humans thrive alongside AI that’s much smarter than us? I’ll argue that intent alignment might be extremely hard to achieve, and that it’s *neither necessary nor sufficient* for a good future. Our best shot at a good future is to not build superhuman AI.\nCoordinating not to build superhuman AI would require international treaties, regulation, and monitoring. Coordination is hard, but not as hard as any form of AI alignment! Since coordination failures sometimes happen, it would be wise to have a backup plan based on value alignment. I’ll describe a new benchmark called [EigenBench](https://arxiv.org/abs/2509.01938), which uses a pagerank-inspired algorithm to measure a language model's alignment to a given set of values.",
        "speakers": []
    },
    {
        "name": "Benchmarking Beyond Borders: Making AI Testing Truly Global",
        "short_description": "An event focused on advancing global approaches and standards for evaluating the performance and fairness of AI systems.",
        "event_url": "https://cdt.org/event/benchmarking-beyond-borders-making-ai-testing-truly-global/",
        "category": [
            "Seminar"
        ],
        "image_url": "",
        "start_date": "2026-01-29",
        "end_date": "2026-01-29",
        "location": "Virtual",
        "zoom_url": "",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Artificial Intelligence and the Global South: Perils, Pitfalls and Potential",
        "short_description": "This conference examines the social, political, environmental, and economic impacts of AI in and for the Global South.",
        "event_url": "https://events.cornell.edu/event/institute-for-african-development-spring-symposium-artificial-intelligence-and-the-global-south-perils-pitfalls-and-potential",
        "category": [
            "Conference"
        ],
        "image_url": "",
        "start_date": "2026-04-22",
        "end_date": "2026-04-23",
        "location": "401 Warren Hall, Cornell University",
        "zoom_url": "",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Thought Summit: LLMs And Society",
        "short_description": "A 3-day thought summit exploring the future of LLMs in high-stakes settings.",
        "event_url": "https://globalai.ai.cornell.edu/thought-summit/",
        "category": [
            "Conference"
        ],
        "image_url": "",
        "start_date": "2025-05-19",
        "end_date": "2025-05-22",
        "location": "ILR Conference Center, Cornell University",
        "zoom_url": "",
        "abstract": "",
        "speakers": []
    }
]