[
    {
        "name": "Global AI Seminar: Measuring AI Values",
        "short_description": "**Lionel Levine** is a Professor of Mathematics at Cornell University. He is a Fellow of the American Mathematical Society, and a past recipient of a Sloan Fellowship, NSF CAREER Award, and IAS Von Neumann Fellowship. His current research is aimed at increasing the probability that future AI systems benefit all of humanity and the planet.",
        "event_url": "",
        "category": [
            "Seminar"
        ],
        "image_url": "https://pi.math.cornell.edu/~levine/lionel-levine-cornell-2.jpg",
        "start_date": "2026-02-24",
        "end_date": "2026-02-24",
        "time": "3:00 PM - 4:00 PM ET",
        "location": "Gates 203 | Virtual",
        "zoom_url": "https://cornell.zoom.us/j/3811699431?pwd=OHlGaG1Xa2s2STRucFVJMWpreW95UT09&omn=91507729998",
        "abstract": "Aligning AI with human values is a pressing unsolved problem. But what exactly does it mean to align an AI to a given set of values? And how would one verify that a given AI is aligned? These hard questions, plus the annoying little issue of *whose* values to prioritize, led researchers at leading AI labs to aim instead for “intent alignment”: AI that (wants to) do what its developers intend.\nCan intent alignment deliver a good future, where humans thrive alongside AI that’s much smarter than us? I’ll argue that intent alignment might be extremely hard to achieve, and that it’s *neither necessary nor sufficient* for a good future. Our best shot at a good future is to not build superhuman AI.\nCoordinating not to build superhuman AI would require international treaties, regulation, and monitoring. Coordination is hard, but not as hard as any form of AI alignment! Since coordination failures sometimes happen, it would be wise to have a backup plan based on value alignment. I’ll describe a new benchmark called [EigenBench](https://arxiv.org/abs/2509.01938), which uses a pagerank-inspired algorithm to measure a language model's alignment to a given set of values.",
        "speakers": []
    },
    {
        "name": "Benchmarking Beyond Borders: Making AI Testing Truly Global",
        "short_description": "An event focused on advancing global approaches and standards for evaluating the performance and fairness of AI systems.",
        "event_url": "https://cdt.org/event/benchmarking-beyond-borders-making-ai-testing-truly-global/",
        "category": [
            "Seminar"
        ],
        "image_url": "",
        "start_date": "2026-01-29",
        "end_date": "2026-01-29",
        "location": "Virtual",
        "zoom_url": "",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Artificial Intelligence and the Global South: Perils, Pitfalls and Potential",
        "short_description": "This conference examines the social, political, environmental, and economic impacts of AI in and for the Global South.",
        "event_url": "https://events.cornell.edu/event/institute-for-african-development-spring-symposium-artificial-intelligence-and-the-global-south-perils-pitfalls-and-potential",
        "category": [
            "Conference"
        ],
        "image_url": "",
        "start_date": "2026-04-22",
        "end_date": "2026-04-23",
        "location": "401 Warren Hall, Cornell University",
        "zoom_url": "",
        "abstract": "",
        "speakers": []
    },
    {
        "name": "Thought Summit: LLMs And Society",
        "short_description": "A 3-day thought summit exploring the future of LLMs in high-stakes settings.",
        "event_url": "https://globalai.ai.cornell.edu/thought-summit/",
        "category": [
            "Conference"
        ],
        "image_url": "",
        "start_date": "2025-05-19",
        "end_date": "2025-05-22",
        "location": "ILR Conference Center, Cornell University",
        "zoom_url": "",
        "abstract": "",
        "speakers": []
    }
]